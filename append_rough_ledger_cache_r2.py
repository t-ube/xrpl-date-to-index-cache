#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ—¢å­˜ã® ledger_cache_XXXX.json ã«å¯¾ã—ã¦ã€
æŒ‡å®šã—ãŸæ—¥ä»˜ç¯„å›²ã®ã€Œå­˜åœ¨ã—ãªã„æ—¥ã ã‘ã€ãƒ©ãƒ•å€¤ã‚’è¿½è¨˜ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚

Cloudflare R2 å¯¾å¿œç‰ˆ:
- R2ãƒã‚±ãƒƒãƒˆã‹ã‚‰ç›´æ¥èª­ã¿æ›¸ã
- ç’°å¢ƒå¤‰æ•°ã§èªè¨¼æƒ…å ±ã‚’è¨­å®š

ç’°å¢ƒå¤‰æ•°:
  R2_ACCOUNT_ID: Cloudflareã‚¢ã‚«ã‚¦ãƒ³ãƒˆID
  R2_ACCESS_KEY_ID: R2ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ID
  R2_SECRET_ACCESS_KEY: R2ã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼
  R2_BUCKET_NAME: ãƒã‚±ãƒƒãƒˆå

ä½¿ã„æ–¹:
  python append_rough_ledger_cache.py ledger_cache_2025.json 2025-01-01 2025-12-31
"""

import json
import os
import re
import sys
import time
from datetime import datetime, timedelta, timezone
from io import BytesIO

import boto3
from botocore.config import Config
from xrpl.clients import JsonRpcClient
from xrpl.models.requests import Ledger

# ====== ç’°å¢ƒè¨­å®š ======
GENESIS_INDEX = 32570
RIPPLE_EPOCH = 946684800  # 2000-01-01T00:00:00Z
JSON_RPC_URL = "https://xrplcluster.com/"
client = JsonRpcClient(JSON_RPC_URL)

# ====== R2è¨­å®š ======
R2_ACCOUNT_ID = os.environ.get("R2_ACCOUNT_ID", "")
R2_ACCESS_KEY_ID = os.environ.get("R2_ACCESS_KEY_ID", "")
R2_SECRET_ACCESS_KEY = os.environ.get("R2_SECRET_ACCESS_KEY", "")
R2_BUCKET_NAME = os.environ.get("R2_BUCKET_NAME", "")

def get_r2_client():
    """R2ç”¨ã®boto3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—"""
    if not all([R2_ACCOUNT_ID, R2_ACCESS_KEY_ID, R2_SECRET_ACCESS_KEY]):
        raise ValueError(
            "R2ã®èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
            "ç’°å¢ƒå¤‰æ•° R2_ACCOUNT_ID, R2_ACCESS_KEY_ID, R2_SECRET_ACCESS_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )
    
    return boto3.client(
        "s3",
        endpoint_url=f"https://{R2_ACCOUNT_ID}.r2.cloudflarestorage.com",
        aws_access_key_id=R2_ACCESS_KEY_ID,
        aws_secret_access_key=R2_SECRET_ACCESS_KEY,
        config=Config(
            signature_version="s3v4",
            retries={"max_attempts": 3, "mode": "standard"},
        ),
        region_name="auto",
    )


class FutureLedgerError(Exception):
    """æŒ‡å®šæ—¥æ™‚ã«å¯¾å¿œã™ã‚‹ãƒ¬ã‚¸ãƒ£ãƒ¼ãŒã¾ã å­˜åœ¨ã—ãªã„å ´åˆã«ä½¿ã†ä¾‹å¤–"""
    pass


def ripple_time_to_datetime(ripple_time: int) -> datetime:
    """Rippleã‚¨ãƒãƒƒã‚¯ç§’ â†’ Python datetime (UTC)"""
    return datetime.fromtimestamp(ripple_time + RIPPLE_EPOCH, tz=timezone.utc)


def infer_year_from_path(path: str) -> int | None:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ 4æ¡ã®å¹´ã‚’æ¨æ¸¬ (ä¾‹: ledger_cache_2025.json â†’ 2025)ã€‚
    è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã° Noneã€‚
    """
    m = re.search(r"(\d{4})", os.path.basename(path))
    if m:
        return int(m.group(1))
    return None


def make_empty_cache(path: str, dt_hint: datetime | None = None) -> dict:
    """
    æ–°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ç©ºã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    year ã¯ path ã‹ã‚‰æ¨æ¸¬ã—ã€ç„¡ã‘ã‚Œã° dt_hint.yearã€ã•ã‚‰ã«ç„¡ã‘ã‚Œã° 0ã€‚
    """
    year = infer_year_from_path(path)
    if year is None and dt_hint is not None:
        year = dt_hint.year
    if year is None:
        year = 0

    return {
        "meta": {
            "year": year,
            "version": 1,
        },
        "daily": {},
        "hourly": {},
    }


def migrate_old_flat_format(old: dict, path: str) -> dict:
    """
    æ—§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ãŒ "YYYY-MM-DD" ã‚­ãƒ¼ã® dict) ã‚’
    æ–°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›ã™ã‚‹ã€‚
    """
    cache = make_empty_cache(path)
    daily = cache["daily"]

    for k, v in old.items():
        # "YYYY-MM-DD" ã£ã½ã„ã‚­ãƒ¼ã ã‘æ‹¾ã†
        if isinstance(k, str) and re.match(r"^\d{4}-\d{2}-\d{2}$", k):
            daily[k] = v

    return cache


def load_cache(key: str) -> dict:
    """
    R2ã‹ã‚‰æ—¢å­˜ã®JSONã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª­ã¿è¾¼ã‚€ã€‚
    - ãƒ•ã‚¡ã‚¤ãƒ«ãŒç„¡ã‘ã‚Œã°æ–°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ç©ºã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è¿”ã™ã€‚
    - æ—§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã ã£ãŸå ´åˆã¯æ–°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¸ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã€‚
    
    key: R2ä¸Šã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚­ãƒ¼ (ä¾‹: "ledger_cache_2025.json")
    """
    s3 = get_r2_client()
    
    try:
        response = s3.get_object(Bucket=R2_BUCKET_NAME, Key=key)
        raw = json.loads(response["Body"].read().decode("utf-8"))
        print(f"R2ã‹ã‚‰èª­ã¿è¾¼ã¿å®Œäº†: {key}")
    except s3.exceptions.NoSuchKey:
        print(f"{key} ãŒR2ã«å­˜åœ¨ã—ãªã„ãŸã‚ã€æ–°è¦ä½œæˆã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚")
        return make_empty_cache(key)
    except Exception as e:
        # ClientError ãªã©ã§ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
        if "NoSuchKey" in str(e) or "404" in str(e):
            print(f"{key} ãŒR2ã«å­˜åœ¨ã—ãªã„ãŸã‚ã€æ–°è¦ä½œæˆã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚")
            return make_empty_cache(key)
        raise

    # ã™ã§ã«æ–°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã£ã½ã„
    if isinstance(raw, dict) and "meta" in raw and "daily" in raw:
        # hourly ãŒç„¡ã‘ã‚Œã°è¶³ã—ã¦ãŠã
        raw.setdefault("hourly", {})
        return raw

    # å¤ã„ãƒ•ãƒ©ãƒƒãƒˆå½¢å¼ã¨è¦‹ãªã—ã¦ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    print(f"{key} ã¯æ—§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨ã¿ãªã•ã‚Œã‚‹ãŸã‚ã€æ–°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¸å¤‰æ›ã—ã¾ã™ã€‚")
    return migrate_old_flat_format(raw, key)


def save_cache(key: str, cache: dict) -> None:
    """
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ—¥ä»˜é †ãƒ»æ—¥æ™‚é †ã«ã‚½ãƒ¼ãƒˆã—ã¦R2ã«ä¿å­˜ã€‚
    cache ã¯æ–°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‰æ:
      { "meta": {...}, "daily": {...}, "hourly": {...} }
    
    key: R2ä¸Šã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚­ãƒ¼ (ä¾‹: "ledger_cache_2025.json")
    """
    meta = cache.get("meta", {})
    daily = cache.get("daily", {})
    hourly = cache.get("hourly", {})

    # daily ã¯ã‚­ãƒ¼ (YYYY-MM-DD) ã§ã‚½ãƒ¼ãƒˆ
    daily_sorted = {k: daily[k] for k in sorted(daily.keys())}

    # hourly ã¯ ISOæ–‡å­—åˆ—ã‚­ãƒ¼ã§ã‚½ãƒ¼ãƒˆ
    hourly_sorted = {k: hourly[k] for k in sorted(hourly.keys())}

    out = {
        "meta": meta,
        "daily": daily_sorted,
        "hourly": hourly_sorted,
    }

    json_bytes = json.dumps(out, ensure_ascii=False, indent=2).encode("utf-8")
    
    s3 = get_r2_client()
    s3.put_object(
        Bucket=R2_BUCKET_NAME,
        Key=key,
        Body=BytesIO(json_bytes),
        ContentType="application/json",
    )

    print(f"R2ã«ä¿å­˜å®Œäº†: {key} (daily={len(daily_sorted)}, hourly={len(hourly_sorted)})")


def get_ledger_index_by_date(dt: datetime, max_iter: int = 5) -> tuple[int, datetime]:
    """
    æŒ‡å®šæ—¥æ™‚ã«æœ€ã‚‚è¿‘ã„ ledger index ã‚’ãƒ©ãƒ•ã«æ¨å®šã™ã‚‹ã€‚

    - dt ãŒæœ€æ–°ãƒ¬ã‚¸ãƒ£ãƒ¼ã® close_time ã‚ˆã‚Šæœªæ¥ãªã‚‰ FutureLedgerError ã‚’æŠ•ã’ã‚‹
    - ãã‚Œä»¥å¤–ã¯ã€Œèª¤å·®1æ™‚é–“ä»¥å†…ã€ã®ãƒ©ãƒ•å€¤ã‚’è¿”ã™ï¼ˆå¾Œæ®µã§è£œæ­£å‰æï¼‰
    """
    latest = client.request(Ledger(ledger_index="validated", expand=True)).result
    latest_index = int(latest["ledger_index"])
    latest_time = ripple_time_to_datetime(latest["ledger"]["close_time"])

    # ğŸŸ¡ ã“ã“ã§ã€Œæœªæ¥æ—¥ä»˜ã€ã‚’åˆ¤å®š
    if dt > latest_time:
        raise FutureLedgerError(
            f"target datetime {dt.isoformat()} is newer than latest ledger close_time {latest_time.isoformat()}"
        )

    # åˆæœŸæ¨å®š: 4ç§’/ledger ã¨ä»®å®š
    delta = (latest_time - dt).total_seconds()
    guess_index = latest_index - int(delta / 4)

    close_time = latest_time  # fallback

    for i in range(max_iter):
        res = client.request(Ledger(ledger_index=guess_index, expand=True)).result
        close_time = ripple_time_to_datetime(res["ledger"]["close_time"])

        diff = (close_time - dt).total_seconds()
        print(f"  â†³ iter {i+1}: ledger={guess_index}, close_time={close_time}, diff={diff/3600:.2f}h")

        if abs(diff) < 3600:
            return guess_index, close_time

        guess_index -= int(diff / 4)
        if guess_index < 1:
            guess_index = 1

        time.sleep(0.3)

    return guess_index, close_time


def get_ledger_index_by_date_binary(dt: datetime,
                                    tol_seconds: int = 3600,
                                    max_iter: int = 40) -> tuple[int, datetime]:
    target_date = dt.date()

    # æœ€æ–°ãƒ¬ã‚¸ãƒ£ãƒ¼
    latest = client.request(Ledger(ledger_index="validated", expand=True)).result
    hi_idx = int(latest["ledger_index"])
    hi_time = ripple_time_to_datetime(latest["ledger"]["close_time"])

    # æœªæ¥ãƒã‚§ãƒƒã‚¯
    if dt > hi_time:
        raise FutureLedgerError(
            f"target datetime {dt.isoformat()} is newer than latest ledger close_time {hi_time.isoformat()}"
        )

    # GENESIS ãƒ¬ã‚¸ãƒ£ãƒ¼
    genesis = client.request(Ledger(ledger_index=GENESIS_INDEX, expand=True)).result
    lo_idx = GENESIS_INDEX
    lo_time = ripple_time_to_datetime(genesis["ledger"]["close_time"])

    # GENESIS ã‚ˆã‚Šå‰ã‚’ã©ã†æ‰±ã†ã‹ï¼šã“ã“ã¯ä»•æ§˜æ¬¡ç¬¬
    if dt <= lo_time:
        # 1) å¼·åˆ¶çš„ã« GENESIS ã‚’è¿”ã™
        return GENESIS_INDEX, lo_time

    best_idx = lo_idx
    best_time = lo_time

    for i in range(max_iter):
        mid = (lo_idx + hi_idx) // 2
        res = client.request(Ledger(ledger_index=mid, expand=True)).result
        mid_time = ripple_time_to_datetime(res["ledger"]["close_time"])
        mid_date = mid_time.date()

        # ä¸€ç•ªè¿‘ã„ã‚‚ã®ã‚’è¨˜æ†¶ã—ã¦ãŠã
        if abs((mid_time - dt).total_seconds()) < abs((best_time - dt).total_seconds()):
            best_idx = mid
            best_time = mid_time

        diff = (mid_time - dt).total_seconds()
        print(f"  â†³ iter {i+1}: ledger={mid}, close_time={mid_time}, diff={diff/3600:.2f}h")

        if mid_date == target_date:
            return mid, mid_time

        if mid_time < dt:
            lo_idx = mid + 1
        else:
            hi_idx = mid - 1

        if lo_idx > hi_idx:
            break

        time.sleep(0.3)

    return best_idx, best_time


def append_rough_ledger_cache(key: str, dt_start: datetime, dt_end: datetime) -> None:
    """
    R2ä¸Šã® key ã§æŒ‡å®šã•ã‚ŒãŸ JSON ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆæ–°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰ã«å¯¾ã—ã¦ã€
    [dt_start, dt_end] ã®æ—¥ä»˜ç¯„å›²ã§ã€Œå­˜åœ¨ã—ãªã„ daily ã ã‘ã€ãƒ©ãƒ•å€¤ã‚’è¿½åŠ ã™ã‚‹ã€‚
    å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿ã€æœ€å¾Œã«1å›ä¿å­˜ã™ã‚‹ã€‚
    """
    cache = load_cache(key)
    daily: dict = cache.setdefault("daily", {})
    cache.setdefault("hourly", {})  # ã¾ã ä½¿ã‚ãªã„ãŒå¿µã®ãŸã‚ç¢ºä¿

    cur = dt_start
    total_days = (dt_end.date() - dt_start.date()).days + 1
    processed = 0
    added = 0

    print(f"{dt_start.date()} ï½ {dt_end.date()} ã®ä¸è¶³åˆ†ã‚’ {key} ã® daily ã«è¿½è¨˜ã—ã¾ã™ã€‚")

    while cur <= dt_end:
        processed += 1
        date_key = cur.strftime("%Y-%m-%d")

        if date_key in daily:
            print(f"[{processed}/{total_days}] {date_key}: daily æ—¢å­˜ã‚¨ãƒ³ãƒˆãƒªã‚ã‚Š â†’ ã‚¹ã‚­ãƒƒãƒ—")
        else:
            print(f"[{processed}/{total_days}] {date_key}: daily è¿½åŠ å‡¦ç†é–‹å§‹")
            try:
                idx, close_time = get_ledger_index_by_date(cur)
                daily[date_key] = {
                    "ledger_index": idx,
                    "close_time": close_time.isoformat().replace("+00:00", "Z"),
                }
                added += 1
                print(f"   â†³ è¿½åŠ : ledger={idx}, close_time={close_time}")
                time.sleep(1)  # æˆåŠŸæ™‚ã ã‘ã‚¦ã‚§ã‚¤ãƒˆ
            except FutureLedgerError as e:
                # ã¾ã ãƒ¬ã‚¸ãƒ£ãƒ¼ãŒå­˜åœ¨ã—ãªã„ï¼ˆæœªæ¥æ—¥ä»˜ï¼‰ã®å ´åˆã¯ã€Œæ­£å¸¸ã‚¹ã‚­ãƒƒãƒ—ã€ã¨ã¿ãªã™
                print(f"   â­ æœªæ¥æ—¥ä»˜ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {e}")
                # ã“ã®æ—¥ä»¥é™ã¯å…¨éƒ¨æœªæ¥ç¢ºå®šãªã®ã§ãƒ«ãƒ¼ãƒ—çµ‚äº†ã§ã‚ˆã„
                break
            except Exception as e:
                print(f"   è¿½åŠ å¤±æ•—ï¼ˆåˆ¥åŸå› ï¼‰: {e}")
                time.sleep(3)

        cur += timedelta(days=1)

    print(f"\n å‡¦ç†å®Œäº†: {processed} æ—¥ä¸­ {added} æ—¥ã‚’ daily ã«è¿½åŠ ")
    
    # å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿ä¿å­˜
    if added > 0:
        save_cache(key, cache)
    else:
        print("å¤‰æ›´ãªã—ã®ãŸã‚ä¿å­˜ã‚¹ã‚­ãƒƒãƒ—")


def parse_date(s: str) -> datetime:
    return datetime.strptime(s, "%Y-%m-%d").replace(tzinfo=timezone.utc)


if __name__ == "__main__":
    if len(sys.argv) != 4:
        print("ä½¿ã„æ–¹:")
        print("  python append_rough_ledger_cache.py <r2_key> <start_date> <end_date>")
        print("ä¾‹:")
        print("  python append_rough_ledger_cache.py ledger_cache_2025.json 2025-01-01 2025-12-31")
        print()
        print("ç’°å¢ƒå¤‰æ•°:")
        print("  R2_ACCOUNT_ID       - Cloudflareã‚¢ã‚«ã‚¦ãƒ³ãƒˆID")
        print("  R2_ACCESS_KEY_ID    - R2ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ID")
        print("  R2_SECRET_ACCESS_KEY - R2ã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼")
        print("  R2_BUCKET_NAME      - ãƒã‚±ãƒƒãƒˆå")
        sys.exit(1)

    r2_key = sys.argv[1]
    start_dt = parse_date(sys.argv[2])
    end_dt = parse_date(sys.argv[3])

    append_rough_ledger_cache(r2_key, start_dt, end_dt)
